{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706bd116",
   "metadata": {},
   "source": [
    "# üìö Tabla de contenidos\n",
    "\n",
    "1. [Setup Inicial](#1-setup-inicial)\n",
    "   - 1.1 [Configuraci√≥n ChromaDB](#11-configuracion-chromadb)\n",
    "   - 1.2 [Base de datos Tabular](#12-base-de-datos-tabular)\n",
    "      - 1.2.1 [Funciones de consulta Tabular](#121-funciones-de-consulta-tabular)\n",
    "   - 1.3 [Base de datos de Grafos](#13-base-de-datos-de-grafos)\n",
    "2. [Creaci√≥n del Agente RAG](#2-creacion-del-agente-rag)\n",
    "   - Herramientas (Tools) para el agente\n",
    "   - Pruebas de las herramientas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e78d9a",
   "metadata": {},
   "source": [
    "## Funciones para convertir en tools\n",
    "\n",
    "> - `doc_search(query: str, n_results: int = 5, filter_tipo: Optional[str] = None, use_rerank: bool = True)` -> Dict[str, Any]:\n",
    ">   - B√∫squeda h√≠brida (sem√°ntica + BM25) con re-ranking\n",
    ">   - filter_tipo: Filtrar por tipo de documento ('manual', 'faq', 'ticket', 'resena')\n",
    ">   - use_rerank: Aplicar re-ranking con Cross-Encoder (recomendado: True)\n",
    "> - `consulta_con_llm_tabular(llm, consulta_usuario: str)` -> Any:\n",
    ">   - Consultas en lenguaje natural sobre datos tabulares\n",
    "> - `consulta_grafo(llm, graph_db: MemgraphConnection, consulta_usuario: str, schema_context: str, verbose: bool = False)` -> Tuple[str, pd.DataFrame]:\n",
    ">   - Consultas en lenguaje natural sobre base de datos de grafos\n",
    ">   - `get_schema_context_for_cypher()` -> Funci√≥n para obtener `schema_context`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5034d2",
   "metadata": {},
   "source": [
    "## 1. Setup Inicial\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "066e79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Driver de Neo4j para conectarse a Memgraph\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Para b√∫squeda h√≠brida y re-ranking\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "864ee8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "METADATA_DIR = PROCESSED_DATA_DIR / \"metadata\"\n",
    "CHROMA_DB_DIR = PROCESSED_DATA_DIR / \"chroma_db\"\n",
    "\n",
    "PRODUCTOS_CSV = RAW_DATA_DIR / \"productos.csv\"\n",
    "FAQS_JSON = RAW_DATA_DIR / \"faqs.json\"\n",
    "TICKETS_CSV = RAW_DATA_DIR / \"tickets_soporte.csv\"\n",
    "MANUALES_DIR = RAW_DATA_DIR / \"manuales_productos\"\n",
    "RESENAS_DIR = RAW_DATA_DIR / \"resenas_usuarios\"\n",
    "\n",
    "FUNCIONES_CONTEXT = METADATA_DIR / \"funciones_disponibles_for_llm.txt\"\n",
    "SCHEMA_CONTEXT = METADATA_DIR / \"schema_context_for_llm.txt\"\n",
    "\n",
    "COLLECTION_NAME = \"electrodomesticos_docs\"\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec2514",
   "metadata": {},
   "source": [
    "### 1.1 Configuracion ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e18a96e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB inicializado\n",
      "\n",
      "Colecci√≥n 'electrodomesticos_docs' cargada\n",
      "  Documentos en colecci√≥n: 10165\n"
     ]
    }
   ],
   "source": [
    "CHROMA_DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=str(CHROMA_DB_DIR))\n",
    "\n",
    "print(f\"ChromaDB inicializado\")\n",
    "\n",
    "# Crear o obtener colecci√≥n\n",
    "try:\n",
    "    collection = chroma_client.get_collection(name=COLLECTION_NAME)\n",
    "    print(f\"\\nColecci√≥n '{COLLECTION_NAME}' cargada\")\n",
    "    print(f\"  Documentos en colecci√≥n: {collection.count()}\")\n",
    "except:\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        metadata={\"description\": \"Documentaci√≥n y contenido de electrodom√©sticos\"}\n",
    "    )\n",
    "    print(f\"\\nColecci√≥n '{COLLECTION_NAME}' creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58f81dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
    "    \"\"\"\n",
    "    Divide un texto en chunks con overlap para mejor contexto.\n",
    "    \n",
    "    Args:\n",
    "        text: Texto a dividir\n",
    "        chunk_size: Tama√±o aproximado de cada chunk en caracteres\n",
    "        overlap: Cantidad de caracteres que se solapan entre chunks\n",
    "    \n",
    "    Returns:\n",
    "        Lista de chunks de texto\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def load_manuales() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Carga todos los manuales de productos.\"\"\"\n",
    "    documentos = []\n",
    "    \n",
    "    if not MANUALES_DIR.exists():\n",
    "        print(f\"Directorio de manuales no encontrado: {MANUALES_DIR}\")\n",
    "        return documentos\n",
    "    \n",
    "    for manual_file in MANUALES_DIR.glob(\"*.md\"):\n",
    "        try:\n",
    "            with open(manual_file, 'r', encoding='utf-8') as f:\n",
    "                contenido = f.read()\n",
    "            \n",
    "            # Extraer ID del producto del nombre del archivo\n",
    "            product_id = manual_file.stem.split('_')[1] if '_' in manual_file.stem else \"unknown\"\n",
    "            \n",
    "            # Dividir en chunks\n",
    "            chunks = chunk_text(contenido, chunk_size=500, overlap=50)\n",
    "            \n",
    "            for idx, chunk in enumerate(chunks):\n",
    "                documentos.append({\n",
    "                    'id': f\"manual_{product_id}_chunk_{idx}\",\n",
    "                    'text': chunk,\n",
    "                    'metadata': {\n",
    "                        'tipo': 'manual',\n",
    "                        'producto_id': product_id,\n",
    "                        'archivo': manual_file.name,\n",
    "                        'chunk': idx\n",
    "                    }\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando {manual_file.name}: {e}\")\n",
    "    \n",
    "    return documentos\n",
    "\n",
    "def load_faqs() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Carga las FAQs desde el archivo JSON.\"\"\"\n",
    "    documentos = []\n",
    "    \n",
    "    if not FAQS_JSON.exists():\n",
    "        print(f\"‚ö† Archivo FAQs no encontrado: {FAQS_JSON}\")\n",
    "        return documentos\n",
    "    \n",
    "    try:\n",
    "        with open(FAQS_JSON, 'r', encoding='utf-8') as f:\n",
    "            faqs = json.load(f)\n",
    "        \n",
    "        for idx, faq in enumerate(faqs):\n",
    "            # Combinar pregunta y respuesta\n",
    "            texto = f\"Pregunta: {faq.get('pregunta', '')}\\nRespuesta: {faq.get('respuesta', '')}\"\n",
    "            \n",
    "            documentos.append({\n",
    "                'id': f\"faq_{idx}\",\n",
    "                'text': texto,\n",
    "                'metadata': {\n",
    "                    'tipo': 'faq',\n",
    "                    'categoria': faq.get('categoria', 'general')\n",
    "                }\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando FAQs: {e}\")\n",
    "    \n",
    "    return documentos\n",
    "\n",
    "def load_tickets() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Carga los tickets de soporte.\"\"\"\n",
    "    documentos = []\n",
    "    \n",
    "    if not TICKETS_CSV.exists():\n",
    "        print(f\"Archivo tickets no encontrado: {TICKETS_CSV}\")\n",
    "        return documentos\n",
    "    \n",
    "    try:\n",
    "        df_tickets = pd.read_csv(TICKETS_CSV)\n",
    "        \n",
    "        for idx, row in df_tickets.iterrows():\n",
    "            # Combinar problema y soluci√≥n\n",
    "            texto = f\"Problema: {row.get('problema', '')}\\nSoluci√≥n: {row.get('solucion', '')}\"\n",
    "            \n",
    "            documentos.append({\n",
    "                'id': f\"ticket_{idx}\",\n",
    "                'text': texto,\n",
    "                'metadata': {\n",
    "                    'tipo': 'ticket',\n",
    "                    'producto_id': row.get('id_producto', 'unknown'),\n",
    "                    'estado': row.get('estado', 'unknown')\n",
    "                }\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando tickets: {e}\")\n",
    "    \n",
    "    return documentos\n",
    "\n",
    "def load_resenas() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Carga las rese√±as de usuarios.\"\"\"\n",
    "    documentos = []\n",
    "    \n",
    "    if not RESENAS_DIR.exists():\n",
    "        print(f\" Directorio de rese√±as no encontrado: {RESENAS_DIR}\")\n",
    "        return documentos\n",
    "    \n",
    "    for resena_file in RESENAS_DIR.glob(\"*.txt\"):\n",
    "        try:\n",
    "            with open(resena_file, 'r', encoding='utf-8') as f:\n",
    "                contenido = f.read()\n",
    "            \n",
    "            # Extraer ID del producto del nombre del archivo\n",
    "            product_id = resena_file.stem.replace('resenas_', '')\n",
    "            \n",
    "            documentos.append({\n",
    "                'id': f\"resena_{product_id}\",\n",
    "                'text': contenido,\n",
    "                'metadata': {\n",
    "                    'tipo': 'resena',\n",
    "                    'producto_id': product_id\n",
    "                }\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando {resena_file.name}: {e}\")\n",
    "    \n",
    "    return documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "658d2b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base vectorial ya contiene 10165 documentos\n",
      "Para recargar, elimina la colecci√≥n primero\n"
     ]
    }
   ],
   "source": [
    "def populate_vector_db():\n",
    "    \"\"\"Carga todos los documentos en ChromaDB.\"\"\"\n",
    "    \n",
    "    # Cargar todos los documentos\n",
    "    all_docs = []\n",
    "    \n",
    "    print(\"\\n1. Cargando manuales...\")\n",
    "    manuales = load_manuales()\n",
    "    print(f\"   {len(manuales)} chunks de manuales cargados\")\n",
    "    all_docs.extend(manuales)\n",
    "    \n",
    "    print(\"\\n2. Cargando FAQs...\")\n",
    "    faqs = load_faqs()\n",
    "    print(f\"   {len(faqs)} FAQs cargadas\")\n",
    "    all_docs.extend(faqs)\n",
    "    \n",
    "    print(\"\\n3. Cargando tickets de soporte...\")\n",
    "    tickets = load_tickets()\n",
    "    print(f\"   {len(tickets)} tickets cargados\")\n",
    "    all_docs.extend(tickets)\n",
    "    \n",
    "    print(\"\\n4. Cargando rese√±as...\")\n",
    "    resenas = load_resenas()\n",
    "    print(f\"   {len(resenas)} rese√±as cargadas\")\n",
    "    all_docs.extend(resenas)\n",
    "    \n",
    "    if not all_docs:\n",
    "        print(\"No se encontraron documentos para cargar\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nTotal de documentos: {len(all_docs)}\")\n",
    "    \n",
    "    ids = [doc['id'] for doc in all_docs]\n",
    "    texts = [doc['text'] for doc in all_docs]\n",
    "    metadatas = [doc['metadata'] for doc in all_docs]\n",
    "    \n",
    "    print(\"\\nInsertando documentos en ChromaDB...\")\n",
    "    \n",
    "    batch_size = 100\n",
    "    for i in range(0, len(all_docs), batch_size):\n",
    "        batch_end = min(i + batch_size, len(all_docs))\n",
    "        \n",
    "        collection.add(\n",
    "            ids=ids[i:batch_end],\n",
    "            documents=texts[i:batch_end],\n",
    "            metadatas=metadatas[i:batch_end]\n",
    "        )\n",
    "        \n",
    "        print(f\"Procesados {batch_end}/{len(all_docs)} documentos\")\n",
    "        \n",
    "    print(f\"\\nBase vectorial poblada exitosamente\")\n",
    "    print(f\"Total documentos en colecci√≥n: {collection.count()}\")\n",
    "\n",
    "\n",
    "if collection.count() == 0:\n",
    "    populate_vector_db()\n",
    "else:\n",
    "    print(f\"Base vectorial ya contiene {collection.count()} documentos\")\n",
    "    print(\"Para recargar, elimina la colecci√≥n primero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95d63ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INICIALIZANDO SISTEMA DE B√öSQUEDA H√çBRIDA CON RE-RANKING\n",
      "================================================================================\n",
      "Inicializando BM25...\n",
      "Cargando modelo de Re-Ranking: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Cargando modelo de Re-Ranking: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "  - Peso b√∫squeda sem√°ntica: 60%\n",
      "  - Peso b√∫squeda BM25: 40%\n",
      "  - Peso b√∫squeda sem√°ntica: 60%\n",
      "  - Peso b√∫squeda BM25: 40%\n"
     ]
    }
   ],
   "source": [
    "class HybridSearchWithReRank:\n",
    "    \"\"\"\n",
    "    Sistema de b√∫squeda h√≠brida que combina:\n",
    "    - B√∫squeda sem√°ntica (ChromaDB)\n",
    "    - B√∫squeda por palabras clave (BM25)\n",
    "    - Re-ranking con Cross-Encoder\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chroma_collection, alpha=0.6, reranker_model='cross-encoder/ms-marco-MiniLM-L-6-v2'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            chroma_collection: Colecci√≥n de ChromaDB\n",
    "            alpha: Peso para b√∫squeda sem√°ntica (1-alpha para BM25)\n",
    "            reranker_model: Modelo Cross-Encoder para re-ranking\n",
    "        \"\"\"\n",
    "        self.collection = chroma_collection\n",
    "        self.alpha = alpha\n",
    "        self.bm25 = None\n",
    "        self.corpus = []\n",
    "        self.metadata = []\n",
    "        self.reranker = None\n",
    "        self._initialize_bm25()\n",
    "        self._initialize_reranker(reranker_model)\n",
    "    \n",
    "    def _initialize_bm25(self):\n",
    "        \"\"\"Inicializa BM25 con todos los documentos de ChromaDB\"\"\"\n",
    "        print(\"Inicializando BM25...\")\n",
    "        all_data = self.collection.get(include=['documents', 'metadatas'])\n",
    "        self.corpus = all_data['documents']\n",
    "        self.metadata = all_data['metadatas']\n",
    "        \n",
    "        # Tokenizar corpus\n",
    "        tokenized_corpus = [self._tokenize(doc) for doc in self.corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "    \n",
    "    def _initialize_reranker(self, model_name):\n",
    "        \"\"\"Inicializa el modelo de re-ranking\"\"\"\n",
    "        print(f\"Cargando modelo de Re-Ranking: {model_name}\")\n",
    "        self.reranker = CrossEncoder(model_name)\n",
    "    \n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Tokeniza texto para BM25\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        return text.split()\n",
    "    \n",
    "    def _normalize_scores(self, scores: List[float]) -> List[float]:\n",
    "        \"\"\"Normaliza scores al rango [0, 1]\"\"\"\n",
    "        if not scores or len(scores) == 1:\n",
    "            return [1.0] * len(scores)\n",
    "        min_s, max_s = min(scores), max(scores)\n",
    "        if max_s == min_s:\n",
    "            return [1.0] * len(scores)\n",
    "        return [(s - min_s) / (max_s - min_s) for s in scores]\n",
    "    \n",
    "    def search(self, query: str, n_results: int = 5, filter_tipo: Optional[str] = None, \n",
    "               use_rerank: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        B√∫squeda h√≠brida con re-ranking\n",
    "        \n",
    "        Args:\n",
    "            query: Consulta del usuario\n",
    "            n_results: N√∫mero de resultados finales\n",
    "            filter_tipo: Filtrar por tipo ('manual', 'faq', 'ticket', 'resena')\n",
    "            use_rerank: Aplicar re-ranking con Cross-Encoder\n",
    "        \n",
    "        Returns:\n",
    "            Dict con resultados rankeados\n",
    "        \"\"\"\n",
    "        # 1. B√∫squeda sem√°ntica (ChromaDB)\n",
    "        where_clause = {\"tipo\": filter_tipo} if filter_tipo else None\n",
    "        semantic_results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=n_results * 3,  # Recuperar m√°s para re-ranking\n",
    "            where=where_clause\n",
    "        )\n",
    "        \n",
    "        # 2. B√∫squeda BM25\n",
    "        tokenized_query = self._tokenize(query)\n",
    "        bm25_scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        # Aplicar filtro si existe\n",
    "        if filter_tipo:\n",
    "            filtered_indices = [i for i, meta in enumerate(self.metadata) \n",
    "                              if meta.get('tipo') == filter_tipo]\n",
    "        else:\n",
    "            filtered_indices = list(range(len(self.corpus)))\n",
    "        \n",
    "        # Top documentos BM25\n",
    "        bm25_top_indices = sorted(filtered_indices, \n",
    "                                  key=lambda i: bm25_scores[i], \n",
    "                                  reverse=True)[:n_results * 3]\n",
    "        \n",
    "        # 3. Combinar resultados\n",
    "        combined = {}\n",
    "        \n",
    "        # Procesar resultados sem√°nticos\n",
    "        if semantic_results['documents'] and semantic_results['documents'][0]:\n",
    "            sem_docs = semantic_results['documents'][0]\n",
    "            sem_meta = semantic_results['metadatas'][0]\n",
    "            sem_distances = semantic_results['distances'][0]\n",
    "            sem_scores_norm = self._normalize_scores([1 - d for d in sem_distances])\n",
    "            \n",
    "            for doc, meta, score in zip(sem_docs, sem_meta, sem_scores_norm):\n",
    "                doc_key = doc[:100]\n",
    "                combined[doc_key] = {\n",
    "                    'document': doc,\n",
    "                    'metadata': meta,\n",
    "                    'sem_score': score,\n",
    "                    'bm25_score': 0.0\n",
    "                }\n",
    "        \n",
    "        # Procesar resultados BM25\n",
    "        bm25_scores_filtered = [bm25_scores[i] for i in bm25_top_indices if bm25_scores[i] > 0]\n",
    "        if bm25_scores_filtered:\n",
    "            bm25_scores_norm = self._normalize_scores(bm25_scores_filtered)\n",
    "            for idx, score in zip(bm25_top_indices, bm25_scores_norm):\n",
    "                if bm25_scores[idx] > 0:\n",
    "                    doc = self.corpus[idx]\n",
    "                    doc_key = doc[:100]\n",
    "                    if doc_key not in combined:\n",
    "                        combined[doc_key] = {\n",
    "                            'document': doc,\n",
    "                            'metadata': self.metadata[idx],\n",
    "                            'sem_score': 0.0,\n",
    "                            'bm25_score': score\n",
    "                        }\n",
    "                    else:\n",
    "                        combined[doc_key]['bm25_score'] = max(combined[doc_key]['bm25_score'], score)\n",
    "        \n",
    "        # 4. Score h√≠brido\n",
    "        hybrid_results = []\n",
    "        for data in combined.values():\n",
    "            hybrid_score = self.alpha * data['sem_score'] + (1 - self.alpha) * data['bm25_score']\n",
    "            hybrid_results.append((data['document'], data['metadata'], hybrid_score))\n",
    "        \n",
    "        hybrid_results.sort(key=lambda x: x[2], reverse=True)\n",
    "        hybrid_results = hybrid_results[:n_results * 2]  # Reducir antes de re-ranking\n",
    "        \n",
    "        # 5. Re-Ranking con Cross-Encoder\n",
    "        if use_rerank and hybrid_results:\n",
    "            query_doc_pairs = [(query, doc) for doc, _, _ in hybrid_results]\n",
    "            rerank_scores = self.reranker.predict(query_doc_pairs)\n",
    "            \n",
    "            final_results = [(doc, meta, float(score)) \n",
    "                           for (doc, meta, _), score in zip(hybrid_results, rerank_scores)]\n",
    "            final_results.sort(key=lambda x: x[2], reverse=True)\n",
    "        else:\n",
    "            final_results = hybrid_results\n",
    "        \n",
    "        # 6. Formatear salida\n",
    "        return {\n",
    "            'query': query,\n",
    "            'n_results': min(len(final_results), n_results),\n",
    "            'method': 'hybrid_with_rerank' if use_rerank else 'hybrid',\n",
    "            'documents': [\n",
    "                {\n",
    "                    'text': doc,\n",
    "                    'metadata': meta,\n",
    "                    'score': score\n",
    "                }\n",
    "                for doc, meta, score in final_results[:n_results]\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Inicializar sistema de b√∫squeda h√≠brida\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INICIALIZANDO SISTEMA DE B√öSQUEDA H√çBRIDA CON RE-RANKING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "hybrid_search = HybridSearchWithReRank(\n",
    "    chroma_collection=collection,\n",
    "    alpha=0.6  # 60% sem√°ntico, 40% BM25\n",
    ")\n",
    "\n",
    "print(f\"  - Peso b√∫squeda sem√°ntica: 60%\")\n",
    "print(f\"  - Peso b√∫squeda BM25: 40%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e56dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PRUEBA DE doc_search() - B√öSQUEDA H√çBRIDA CON RE-RANKING\n",
      "================================================================================\n",
      "\n",
      "Consulta: '¬øC√≥mo se limpia una licuadora?'\n",
      "\n",
      "Buscando...\n",
      "\n",
      "Resultados encontrados: 3\n",
      "M√©todo: hybrid_with_rerank\n",
      "\n",
      "Top 3 documentos:\n",
      "\n",
      "1. Score: 7.2933\n",
      "   Tipo: faq\n",
      "   Texto: Pregunta: ¬øC√≥mo se limpia?\n",
      "Respuesta: Para limpiar el Licuadora, descon√©ctelo primero. Las piezas removibles pueden lavarse con agua tibia y jab√≥n. La...\n",
      "\n",
      "2. Score: 7.2307\n",
      "   Tipo: faq\n",
      "   Texto: Pregunta: ¬øC√≥mo se limpia?\n",
      "Respuesta: Para limpiar el Ultra Licuadora, descon√©ctelo primero. Las piezas removibles pueden lavarse con agua tibia y jab...\n",
      "\n",
      "3. Score: 7.0452\n",
      "   Tipo: faq\n",
      "   Texto: Pregunta: ¬øC√≥mo se limpia?\n",
      "Respuesta: Para limpiar el Plus Licuadora Pro, descon√©ctelo primero. Las piezas removibles pueden lavarse con agua tibia y ...\n",
      "\n",
      "\n",
      "Resultados encontrados: 3\n",
      "M√©todo: hybrid_with_rerank\n",
      "\n",
      "Top 3 documentos:\n",
      "\n",
      "1. Score: 7.2933\n",
      "   Tipo: faq\n",
      "   Texto: Pregunta: ¬øC√≥mo se limpia?\n",
      "Respuesta: Para limpiar el Licuadora, descon√©ctelo primero. Las piezas removibles pueden lavarse con agua tibia y jab√≥n. La...\n",
      "\n",
      "2. Score: 7.2307\n",
      "   Tipo: faq\n",
      "   Texto: Pregunta: ¬øC√≥mo se limpia?\n",
      "Respuesta: Para limpiar el Ultra Licuadora, descon√©ctelo primero. Las piezas removibles pueden lavarse con agua tibia y jab...\n",
      "\n",
      "3. Score: 7.0452\n",
      "   Tipo: faq\n",
      "   Texto: Pregunta: ¬øC√≥mo se limpia?\n",
      "Respuesta: Para limpiar el Plus Licuadora Pro, descon√©ctelo primero. Las piezas removibles pueden lavarse con agua tibia y ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def doc_search(query: str, n_results: int = 5, filter_tipo: Optional[str] = None, \n",
    "               use_rerank: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    B√∫squeda avanzada en documentos con b√∫squeda h√≠brida y re-ranking.\n",
    "    \n",
    "    Combina:\n",
    "    - B√∫squeda sem√°ntica (embeddings con ChromaDB)\n",
    "    - B√∫squeda por palabras clave (BM25)\n",
    "    - Re-ranking con Cross-Encoder para mejorar relevancia\n",
    "    \n",
    "    Args:\n",
    "        query: Consulta del usuario\n",
    "        n_results: N√∫mero de resultados a retornar\n",
    "        filter_tipo: Filtrar por tipo ('manual', 'faq', 'ticket', 'resena')\n",
    "        use_rerank: Aplicar re-ranking (recomendado: True)\n",
    "    \n",
    "    Returns:\n",
    "        Dict con:\n",
    "        - query: consulta original\n",
    "        - n_results: n√∫mero de resultados\n",
    "        - method: m√©todo usado (hybrid_with_rerank o hybrid)\n",
    "        - documents: lista de documentos con text, metadata y score\n",
    "    \"\"\"\n",
    "    return hybrid_search.search(query, n_results, filter_tipo, use_rerank)\n",
    "\n",
    "\n",
    "# Prueba de la funci√≥n\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRUEBA DE doc_search() - B√öSQUEDA H√çBRIDA CON RE-RANKING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_query = \"¬øC√≥mo se limpia una licuadora?\"\n",
    "print(f\"\\nConsulta: '{test_query}'\")\n",
    "print(\"\\nBuscando...\")\n",
    "\n",
    "results = doc_search(test_query, n_results=3, use_rerank=True)\n",
    "\n",
    "print(f\"\\nResultados encontrados: {results['n_results']}\")\n",
    "print(f\"M√©todo: {results['method']}\")\n",
    "print(\"\\nTop 3 documentos:\\n\")\n",
    "\n",
    "for i, doc in enumerate(results['documents'], 1):\n",
    "    print(f\"{i}. Score: {doc['score']:.4f}\")\n",
    "    print(f\"   Tipo: {doc['metadata'].get('tipo', 'N/A')}\")\n",
    "    print(f\"   Texto: {doc['text'][:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49ca40",
   "metadata": {},
   "source": [
    "## 1.2 Base de datos Tabular\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1b583ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 productos cargados\n",
      "\n",
      "Columnas disponibles:\n",
      "  - id_producto\n",
      "  - nombre\n",
      "  - categoria\n",
      "  - subcategoria\n",
      "  - marca\n",
      "  - precio_usd\n",
      "  - stock\n",
      "  - color\n",
      "  - potencia_w\n",
      "  - capacidad\n",
      "  - voltaje\n",
      "  - peso_kg\n",
      "  - garantia_meses\n",
      "  - descripcion\n",
      "\n",
      "Ejemplo de productos:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id_producto",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nombre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "categoria",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subcategoria",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "marca",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "precio_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stock",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "color",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "potencia_w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "capacidad",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "voltaje",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "peso_kg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "garantia_meses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "descripcion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0093f198-8250-4087-b97b-1cb19714fbc7",
       "rows": [
        [
         "0",
         "P0001",
         "Licuadora",
         "Cocina",
         "Preparaci√≥n",
         "TechHome",
         "283.63",
         "108",
         "Blanco",
         "650.0",
         "1.2L",
         "12V",
         "5.6",
         "36",
         "Descubr√≠ el poder de la Licuadora de TechHome, dise√±ada para transformar tu experiencia en la cocina. Con su motor de 650W, esta licuadora procesa ingredientes con una eficiencia incomparable. Su jarra de 1.2L est√° fabricada en vidrio borosilicato resistente a altas temperaturas, garantizando durabilidad y seguridad alimentaria. Las cuchillas de acero inoxidable 304 quir√∫rgico mantienen su filo incluso despu√©s de a√±os de uso intensivo. El sistema de 5 velocidades m√°s funci√≥n pulse te permite controlar la textura desde smoothies sedosos hasta salsas con trozos. El dise√±o ergon√≥mico del mango proporciona un agarre c√≥modo y seguro, mientras que la base antideslizante con ventosas mantiene la licuadora estable durante el uso. Incluye tapa medidora transparente para agregar ingredientes durante el licuado. F√°cil de limpiar gracias a su funci√≥n de autolimpieza y piezas aptas para lavavajillas. Ideal para preparar batidos, sopas, salsas, pur√©s, jugos y mucho m√°s. Consumo energ√©tico clase A++, ahorrando hasta un 40% de electricidad. Certificaciones: ISO 9001, CE, RoHS. Garant√≠a extendida de 36 meses. "
        ],
        [
         "1",
         "P0002",
         "Licuadora",
         "Cocina",
         "Preparaci√≥n",
         "TechHome",
         "1273.06",
         "114",
         "Rosa",
         "300.0",
         "2.0L",
         "220V",
         "35.9",
         "36",
         "Descubr√≠ el poder de la Licuadora de TechHome, dise√±ada para transformar tu experiencia en la cocina. Con su motor de 300W, esta licuadora procesa ingredientes con una eficiencia incomparable. Su jarra de 2.0L est√° fabricada en vidrio borosilicato resistente a altas temperaturas, garantizando durabilidad y seguridad alimentaria. Las cuchillas de acero inoxidable 304 quir√∫rgico mantienen su filo incluso despu√©s de a√±os de uso intensivo. El sistema de 5 velocidades m√°s funci√≥n pulse te permite controlar la textura desde smoothies sedosos hasta salsas con trozos. El dise√±o ergon√≥mico del mango proporciona un agarre c√≥modo y seguro, mientras que la base antideslizante con ventosas mantiene la licuadora estable durante el uso. Incluye tapa medidora transparente para agregar ingredientes durante el licuado. F√°cil de limpiar gracias a su funci√≥n de autolimpieza y piezas aptas para lavavajillas. Ideal para preparar batidos, sopas, salsas, pur√©s, jugos y mucho m√°s. Consumo energ√©tico clase A++, ahorrando hasta un 40% de electricidad. Certificaciones: ISO 9001, CE, RoHS. Garant√≠a extendida de 36 meses. "
        ],
        [
         "2",
         "P0003",
         "Plus Licuadora Pro",
         "Cocina",
         "Preparaci√≥n",
         "TechHome",
         "329.07",
         "97",
         "Negro",
         "700.0",
         "1.2L",
         "220V",
         "47.9",
         "18",
         "Descubr√≠ el poder de la Plus Licuadora Pro de TechHome, dise√±ada para transformar tu experiencia en la cocina. Con su motor de 700W, esta licuadora procesa ingredientes con una eficiencia incomparable. Su jarra de 1.2L est√° fabricada en vidrio borosilicato resistente a altas temperaturas, garantizando durabilidad y seguridad alimentaria. Las cuchillas de acero inoxidable 304 quir√∫rgico mantienen su filo incluso despu√©s de a√±os de uso intensivo. El sistema de 5 velocidades m√°s funci√≥n pulse te permite controlar la textura desde smoothies sedosos hasta salsas con trozos. El dise√±o ergon√≥mico del mango proporciona un agarre c√≥modo y seguro, mientras que la base antideslizante con ventosas mantiene la licuadora estable durante el uso. Incluye tapa medidora transparente para agregar ingredientes durante el licuado. F√°cil de limpiar gracias a su funci√≥n de autolimpieza y piezas aptas para lavavajillas. Ideal para preparar batidos, sopas, salsas, pur√©s, jugos y mucho m√°s. Consumo energ√©tico clase A++, ahorrando hasta un 40% de electricidad. Certificaciones: ISO 9001, CE, RoHS. Garant√≠a extendida de 18 meses. "
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_producto</th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>marca</th>\n",
       "      <th>precio_usd</th>\n",
       "      <th>stock</th>\n",
       "      <th>color</th>\n",
       "      <th>potencia_w</th>\n",
       "      <th>capacidad</th>\n",
       "      <th>voltaje</th>\n",
       "      <th>peso_kg</th>\n",
       "      <th>garantia_meses</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>Licuadora</td>\n",
       "      <td>Cocina</td>\n",
       "      <td>Preparaci√≥n</td>\n",
       "      <td>TechHome</td>\n",
       "      <td>283.63</td>\n",
       "      <td>108</td>\n",
       "      <td>Blanco</td>\n",
       "      <td>650.0</td>\n",
       "      <td>1.2L</td>\n",
       "      <td>12V</td>\n",
       "      <td>5.6</td>\n",
       "      <td>36</td>\n",
       "      <td>Descubr√≠ el poder de la Licuadora de TechHome,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0002</td>\n",
       "      <td>Licuadora</td>\n",
       "      <td>Cocina</td>\n",
       "      <td>Preparaci√≥n</td>\n",
       "      <td>TechHome</td>\n",
       "      <td>1273.06</td>\n",
       "      <td>114</td>\n",
       "      <td>Rosa</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.0L</td>\n",
       "      <td>220V</td>\n",
       "      <td>35.9</td>\n",
       "      <td>36</td>\n",
       "      <td>Descubr√≠ el poder de la Licuadora de TechHome,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0003</td>\n",
       "      <td>Plus Licuadora Pro</td>\n",
       "      <td>Cocina</td>\n",
       "      <td>Preparaci√≥n</td>\n",
       "      <td>TechHome</td>\n",
       "      <td>329.07</td>\n",
       "      <td>97</td>\n",
       "      <td>Negro</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1.2L</td>\n",
       "      <td>220V</td>\n",
       "      <td>47.9</td>\n",
       "      <td>18</td>\n",
       "      <td>Descubr√≠ el poder de la Plus Licuadora Pro de ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_producto              nombre categoria subcategoria     marca  \\\n",
       "0       P0001           Licuadora    Cocina  Preparaci√≥n  TechHome   \n",
       "1       P0002           Licuadora    Cocina  Preparaci√≥n  TechHome   \n",
       "2       P0003  Plus Licuadora Pro    Cocina  Preparaci√≥n  TechHome   \n",
       "\n",
       "   precio_usd  stock   color  potencia_w capacidad voltaje  peso_kg  \\\n",
       "0      283.63    108  Blanco       650.0      1.2L     12V      5.6   \n",
       "1     1273.06    114    Rosa       300.0      2.0L    220V     35.9   \n",
       "2      329.07     97   Negro       700.0      1.2L    220V     47.9   \n",
       "\n",
       "   garantia_meses                                        descripcion  \n",
       "0              36  Descubr√≠ el poder de la Licuadora de TechHome,...  \n",
       "1              36  Descubr√≠ el poder de la Licuadora de TechHome,...  \n",
       "2              18  Descubr√≠ el poder de la Plus Licuadora Pro de ...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_productos = pd.read_csv(PRODUCTOS_CSV)\n",
    "\n",
    "print(f\"{len(df_productos)} productos cargados\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "for col in df_productos.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nEjemplo de productos:\")\n",
    "df_productos.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6eabbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_metadata_for_llm() -> str:\n",
    "    \"\"\"\n",
    "    Retorna los metadatos del schema en formato texto optimizado para LLM.\n",
    "    Este contexto ser√° usado por el LLM para elegir qu√© funci√≥n llamar.\n",
    "    \n",
    "    Returns:\n",
    "        String con la descripci√≥n completa del schema para contexto del LLM\n",
    "    \"\"\"\n",
    "    with open(SCHEMA_CONTEXT, 'r', encoding='utf-8') as f:\n",
    "      schema_text = f.read()\n",
    "\n",
    "    return schema_text\n",
    "\n",
    "\n",
    "def get_funciones_disponibles_for_llm() -> str:\n",
    "    \"\"\"\n",
    "    Retorna la documentaci√≥n de las funciones disponibles para que el LLM \n",
    "    pueda elegir cu√°l usar y con qu√© par√°metros.\n",
    "    \n",
    "    Returns:\n",
    "        String con la especificaci√≥n de las funciones disponibles\n",
    "    \"\"\"\n",
    "    with open(FUNCIONES_CONTEXT, 'r', encoding='utf-8') as f:\n",
    "      funciones_spec = f.read()\n",
    "    \n",
    "    return funciones_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6abc772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo 1: Schema del Dataset\n",
      "  Tama√±o: 1942 caracteres (~647 tokens)\n",
      "\n",
      "Archivo 2: Funciones Disponibles\n",
      "  Tama√±o: 4917 caracteres (~1639 tokens)\n"
     ]
    }
   ],
   "source": [
    "llm_schema_context = get_schema_metadata_for_llm()\n",
    "llm_funciones_context = get_funciones_disponibles_for_llm()\n",
    "\n",
    "print(f\"\\nArchivo 1: Schema del Dataset\")\n",
    "print(f\"  Tama√±o: {len(llm_schema_context)} caracteres (~{len(llm_schema_context)//3} tokens)\")\n",
    "\n",
    "print(f\"\\nArchivo 2: Funciones Disponibles\")\n",
    "print(f\"  Tama√±o: {len(llm_funciones_context)} caracteres (~{len(llm_funciones_context)//3} tokens)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf6143",
   "metadata": {},
   "source": [
    "#### 1.2.1 Funciones de consulta Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33b4da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_por_precio(precio_min: float = None, precio_max: float = None, \n",
    "                      categoria: str = None, subcategoria: str = None, marca: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Busca productos por rango de precio y opcionalmente por categor√≠a, subcategor√≠a y marca.\n",
    "    \n",
    "    Args:\n",
    "        precio_min: Precio m√≠nimo\n",
    "        precio_max: Precio m√°ximo\n",
    "        categoria: Categor√≠a de producto\n",
    "        subcategoria: Subcategor√≠a de producto\n",
    "        marca: Marca del producto\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con productos filtrados\n",
    "    \"\"\"\n",
    "    df = df_productos.copy()\n",
    "    \n",
    "    if precio_min is not None:\n",
    "        df = df[df['precio_usd'] >= precio_min]\n",
    "    \n",
    "    if precio_max is not None:\n",
    "        df = df[df['precio_usd'] <= precio_max]\n",
    "    \n",
    "    if categoria is not None:\n",
    "        df = df[df['categoria'].str.contains(categoria, case=False, na=False)]\n",
    "    \n",
    "    if subcategoria is not None:\n",
    "        df = df[df['subcategoria'].str.contains(subcategoria, case=False, na=False)]\n",
    "    \n",
    "    if marca is not None:\n",
    "        df = df[df['marca'].str.contains(marca, case=False, na=False)]\n",
    "    \n",
    "    return df.sort_values('precio_usd')\n",
    "\n",
    "def buscar_por_stock(stock_min: int = 0, categoria: str = None, subcategoria: str = None, marca: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Busca productos con stock disponible.\n",
    "    \n",
    "    Args:\n",
    "        stock_min: Stock m√≠nimo requerido\n",
    "        categoria: Categor√≠a de producto\n",
    "        subcategoria: Subcategor√≠a de producto\n",
    "        marca: Marca del producto\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con productos con stock\n",
    "    \"\"\"\n",
    "    df = df_productos[df_productos['stock'] >= stock_min]\n",
    "    \n",
    "    if categoria is not None:\n",
    "        df = df[df['categoria'].str.contains(categoria, case=False, na=False)]\n",
    "    \n",
    "    if subcategoria is not None:\n",
    "        df = df[df['subcategoria'].str.contains(subcategoria, case=False, na=False)]\n",
    "    \n",
    "    if marca is not None:\n",
    "        df = df[df['marca'].str.contains(marca, case=False, na=False)]\n",
    "    \n",
    "    return df.sort_values('stock', ascending=False)\n",
    "\n",
    "def buscar_por_caracteristicas(marca: str = None, categoria: str = None, \n",
    "                               subcategoria: str = None, color: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Busca productos por caracter√≠sticas espec√≠ficas.\n",
    "    \n",
    "    Args:\n",
    "        marca: Marca del producto\n",
    "        categoria: Categor√≠a\n",
    "        subcategoria: Subcategor√≠a\n",
    "        color: Color del producto\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con productos que cumplen los criterios\n",
    "    \"\"\"\n",
    "    df = df_productos.copy()\n",
    "    \n",
    "    if marca is not None:\n",
    "        df = df[df['marca'].str.contains(marca, case=False, na=False)]\n",
    "    \n",
    "    if categoria is not None:\n",
    "        df = df[df['categoria'].str.contains(categoria, case=False, na=False)]\n",
    "    \n",
    "    if subcategoria is not None:\n",
    "        df = df[df['subcategoria'].str.contains(subcategoria, case=False, na=False)]\n",
    "    \n",
    "    if color is not None:\n",
    "        df = df[df['color'].str.contains(color, case=False, na=False)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def comparar_productos(ids_productos: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compara m√∫ltiples productos lado a lado.\n",
    "    \n",
    "    Args:\n",
    "        ids_productos: Lista de IDs de productos a comparar\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con comparaci√≥n de productos\n",
    "    \"\"\"\n",
    "    df = df_productos[df_productos['id_producto'].isin(ids_productos)]\n",
    "    \n",
    "    columnas_importantes = ['id_producto', 'nombre', 'marca', 'precio_usd', \n",
    "                           'stock', 'potencia_w', 'capacidad', 'garantia_meses']\n",
    "    \n",
    "    # Seleccionar solo columnas que existen\n",
    "    columnas_existentes = [col for col in columnas_importantes if col in df.columns]\n",
    "    \n",
    "    return df[columnas_existentes].T\n",
    "\n",
    "def productos_mas_baratos(n: int = 10, categoria: str = None, marca: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retorna los n productos m√°s baratos.\n",
    "    \n",
    "    Args:\n",
    "        n: N√∫mero de productos a retornar\n",
    "        categoria: Filtrar por categor√≠a (opcional)\n",
    "        marca: Filtrar por marca (opcional)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con los productos m√°s baratos\n",
    "    \"\"\"\n",
    "    df = df_productos.copy()\n",
    "    \n",
    "    if categoria is not None:\n",
    "        df = df[df['categoria'].str.contains(categoria, case=False, na=False)]\n",
    "    \n",
    "    if marca is not None:\n",
    "        df = df[df['marca'].str.contains(marca, case=False, na=False)]\n",
    "    \n",
    "    return df.nsmallest(n, 'precio_usd')[['id_producto', 'nombre', 'marca', 'precio_usd', 'stock']]\n",
    "\n",
    "def productos_mas_caros(n: int = 10, categoria: str = None, marca: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retorna los n productos m√°s caros.\n",
    "    \n",
    "    Args:\n",
    "        n: N√∫mero de productos a retornar\n",
    "        categoria: Filtrar por categor√≠a (opcional)\n",
    "        marca: Filtrar por marca (opcional)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con los productos m√°s caros\n",
    "    \"\"\"\n",
    "    df = df_productos.copy()\n",
    "    \n",
    "    if categoria is not None:\n",
    "        df = df[df['categoria'].str.contains(categoria, case=False, na=False)]\n",
    "    \n",
    "    if marca is not None:\n",
    "        df = df[df['marca'].str.contains(marca, case=False, na=False)]\n",
    "    \n",
    "    return df.nlargest(n, 'precio_usd')[['id_producto', 'nombre', 'marca', 'precio_usd', 'stock']]\n",
    "\n",
    "\n",
    "def buscar_por_id(id_producto: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Busca un producto por su ID.\n",
    "    \n",
    "    Args:\n",
    "        id_producto: ID del producto a buscar\n",
    "    \n",
    "    Returns:\n",
    "        Diccionario con informaci√≥n del producto o None si no se encuentra\n",
    "    \"\"\"\n",
    "    producto = df_productos[df_productos['id_producto'] == id_producto]\n",
    "    \n",
    "    if producto.empty:\n",
    "        return None\n",
    "    \n",
    "    return producto.iloc[0].to_dict()\n",
    "\n",
    "def obtener_categorias() -> List[str]:\n",
    "    \"\"\"Retorna lista de todas las categor√≠as disponibles.\"\"\"\n",
    "    return sorted(df_productos['categoria'].unique().tolist())\n",
    "\n",
    "def obtener_marcas() -> List[str]:\n",
    "    \"\"\"Retorna lista de todas las marcas disponibles.\"\"\"\n",
    "    return sorted(df_productos['marca'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "078d7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_prompt_llm_template(schema_context: str = llm_schema_context,\n",
    "                                funciones_context: str = llm_funciones_context) -> PromptTemplate:\n",
    "    \"\"\"\n",
    "    Construye un PromptTemplate donde s√≥lo `consulta_usuario` ser√° variable\n",
    "    al invocarlo.\n",
    "\n",
    "    Usa las variables `llm_schema_context` y `llm_funciones_context` definidas\n",
    "    en el notebook para fijar el contexto del prompt.\n",
    "    \"\"\"\n",
    "    # Escapar llaves para que LangChain no las interprete como variables\n",
    "    schema_escaped = schema_context.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    funciones_escaped = funciones_context.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    \n",
    "    template = f\"\"\"{schema_escaped}\n",
    "\n",
    "---\n",
    "\n",
    "{funciones_escaped}\n",
    "\n",
    "---\n",
    "\n",
    "## CONSULTA DEL USUARIO:\n",
    "{{consulta_usuario}}\n",
    "\n",
    "## TU RESPUESTA (SOLO JSON):\n",
    "\"\"\"\n",
    "    return PromptTemplate(input_variables=[\"consulta_usuario\"], template=template)\n",
    "\n",
    "\n",
    "\n",
    "def invocar_llm_con_consulta(llm, consulta_usuario: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper que crea el chain y ejecuta la consulta.\n",
    "    Retorna el texto devuelto por el LLM (puede ser JSON en texto).\n",
    "    \"\"\"\n",
    "    prompt = crear_prompt_llm_template()\n",
    "    chain = prompt | llm\n",
    "    return chain.invoke({\"consulta_usuario\": consulta_usuario})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37585cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCIONES_DISPONIBLES = {\n",
    "    'buscar_por_precio': buscar_por_precio,\n",
    "    'buscar_por_stock': buscar_por_stock,\n",
    "    'buscar_por_caracteristicas': buscar_por_caracteristicas,\n",
    "    'comparar_productos': comparar_productos,\n",
    "    'productos_mas_baratos': productos_mas_baratos,\n",
    "    'productos_mas_caros': productos_mas_caros,\n",
    "    'obtener_categorias': obtener_categorias,\n",
    "    'buscar_por_id': buscar_por_id,\n",
    "    'obtener_marcas': obtener_marcas\n",
    "}\n",
    "\n",
    "def ejecutar_consulta_tabular(funcion_json: Dict[str, Any]) -> Any:\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta tabular basada en el JSON retornado por el LLM.\n",
    "\n",
    "    Returns:\n",
    "        Resultado de la funci√≥n (generalmente un DataFrame)\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: Si la funci√≥n no existe o hay errores en los par√°metros\n",
    "    \"\"\"\n",
    "    # Validar estructura del JSON\n",
    "    if not isinstance(funcion_json, dict):\n",
    "        raise ValueError(\"El input debe ser un diccionario\")\n",
    "    \n",
    "    if 'funcion' not in funcion_json:\n",
    "        raise ValueError(\"El JSON debe contener la key 'funcion'\")\n",
    "    \n",
    "    if 'parametros' not in funcion_json:\n",
    "        raise ValueError(\"El JSON debe contener la key 'parametros'\")\n",
    "    \n",
    "    nombre_funcion = funcion_json['funcion']\n",
    "    parametros = funcion_json['parametros']\n",
    "    \n",
    "    # Validar que la funci√≥n existe\n",
    "    if nombre_funcion not in FUNCIONES_DISPONIBLES:\n",
    "        funciones_validas = ', '.join(FUNCIONES_DISPONIBLES.keys())\n",
    "        raise ValueError(\n",
    "            f\"Funci√≥n '{nombre_funcion}' no encontrada. \"\n",
    "            f\"Funciones disponibles: {funciones_validas}\"\n",
    "        )\n",
    "    \n",
    "    funcion = FUNCIONES_DISPONIBLES[nombre_funcion]\n",
    "    \n",
    "    try:\n",
    "        resultado = funcion(**parametros)\n",
    "        return resultado\n",
    "    except TypeError as e:\n",
    "        raise ValueError(f\"Error en los par√°metros de '{nombre_funcion}': {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error ejecutando '{nombre_funcion}': {str(e)}\")\n",
    "\n",
    "\n",
    "def consulta_con_llm_tabular(llm, \n",
    "    consulta_usuario: str) -> Any:\n",
    "    \"\"\"\n",
    "    Interfaz principal para realizar consultas en lenguaje natural sobre la base tabular.\n",
    "    \n",
    "    Esta funci√≥n:\n",
    "    1. Prepara el contexto (schema + funciones disponibles) para el LLM\n",
    "    2. Env√≠a la consulta del usuario al LLM\n",
    "    3. El LLM retorna un JSON con la funci√≥n y par√°metros\n",
    "    4. Ejecuta la funci√≥n correspondiente\n",
    "    5. Retorna el resultado\n",
    "\n",
    "    Devuelve:\n",
    "        Resultado de la consulta (generalmente un DataFrame)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2. Llamar al LLM\n",
    "    try:\n",
    "        respuesta_llm = invocar_llm_con_consulta(llm, consulta_usuario)\n",
    "        # 3. Parsear JSON\n",
    "        # El LLM puede retornar JSON en markdown (```json ... ```)\n",
    "        respuesta_limpia = respuesta_llm.strip()\n",
    "        \n",
    "        # Limpiar markdown code blocks si existen\n",
    "        if respuesta_limpia.startswith(\"```\"):\n",
    "            # Encontrar el contenido entre ``` y ```\n",
    "            lineas = respuesta_limpia.split('\\n')\n",
    "            respuesta_limpia = '\\n'.join(lineas[1:-1])\n",
    "        \n",
    "        funcion_json = json.loads(respuesta_limpia)\n",
    "\n",
    "        # 4. Ejecutar la funci√≥n\n",
    "        resultado = ejecutar_consulta_tabular(funcion_json)\n",
    "\n",
    "        return resultado\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Error parseando JSON del LLM: {str(e)}\\nRespuesta: {respuesta_llm}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error en la consulta: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2a46a",
   "metadata": {},
   "source": [
    "## 1.3 Base de datos de Grafos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "472fea55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Conectado a Memgraph en bolt://localhost:7687\n",
      "Nodos en base: 300\n",
      "Relaciones en base: 4500\n",
      "Nodos en base: 300\n",
      "Relaciones en base: 4500\n"
     ]
    }
   ],
   "source": [
    "URI = \"bolt://localhost:7687\"\n",
    "AUTH = (\"\", \"\")  # Sin autenticaci√≥n por defecto en Memgraph\n",
    "\n",
    "class MemgraphConnection:\n",
    "    \"\"\"\n",
    "    Clase para manejar la conexi√≥n y operaciones con Memgraph usando el driver de Neo4j.\n",
    "    Compatible con la sintaxis completa de Cypher.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, uri: str = URI, auth: tuple = AUTH):\n",
    "        \"\"\"\n",
    "        Inicializa la conexi√≥n con Memgraph\n",
    "        \n",
    "        Args:\n",
    "            uri: URI de conexi√≥n (bolt://localhost:7687)\n",
    "            auth: Tupla con (usuario, password)\n",
    "        \"\"\"\n",
    "        self.uri = uri\n",
    "        self.auth = auth\n",
    "        self.driver = None\n",
    "        self._connect()\n",
    "    \n",
    "    def _connect(self):\n",
    "        \"\"\"Establece conexi√≥n con Memgraph\"\"\"\n",
    "        try:\n",
    "            self.driver = GraphDatabase.driver(self.uri, auth=self.auth)\n",
    "            self.driver.verify_connectivity()\n",
    "            print(f\"‚úì Conectado a Memgraph en {self.uri}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error conectando a Memgraph: {e}\")\n",
    "            print(\"\\nAseg√∫rate de que Memgraph est√© corriendo:\")\n",
    "            print(\"  Docker: docker run -p 7687:7687 memgraph/memgraph\")\n",
    "            print(\"  O sigue las instrucciones en: https://memgraph.com/docs/getting-started\")\n",
    "            raise\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Cierra la conexi√≥n\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "            print(\"Conexi√≥n cerrada\")\n",
    "    \n",
    "    def execute_query(self, query: str, parameters: Dict = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Ejecuta una query Cypher y devuelve los resultados\n",
    "        \n",
    "        Args:\n",
    "            query: Query Cypher\n",
    "            parameters: Par√°metros para la query\n",
    "        \n",
    "        Returns:\n",
    "            Lista de diccionarios con los resultados\n",
    "        \"\"\"\n",
    "        if not self.driver:\n",
    "            raise ConnectionError(\"No hay conexi√≥n activa con Memgraph\")\n",
    "        \n",
    "        try:\n",
    "            records, summary, keys = self.driver.execute_query(\n",
    "                query,\n",
    "                parameters_=parameters or {},\n",
    "                database_=\"memgraph\"\n",
    "            )\n",
    "            \n",
    "            # Convertir registros a lista de diccionarios\n",
    "            results = []\n",
    "            for record in records:\n",
    "                result_dict = {}\n",
    "                for key in keys:\n",
    "                    value = record[key]\n",
    "                    # Convertir nodos a diccionarios\n",
    "                    if hasattr(value, '__dict__'):\n",
    "                        result_dict[key] = dict(value)\n",
    "                    else:\n",
    "                        result_dict[key] = value\n",
    "                results.append(result_dict)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error ejecutando query: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def clear_database(self):\n",
    "        \"\"\"Limpia toda la base de datos\"\"\"\n",
    "        try:\n",
    "            self.execute_query(\"MATCH (n) DETACH DELETE n\")\n",
    "            print(\"‚úì Base de datos limpiada\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error limpiando base de datos: {e}\")\n",
    "    \n",
    "    def create_node(self, node_type: str, properties: Dict):\n",
    "        \"\"\"\n",
    "        Crea un nodo en el grafo\n",
    "        \n",
    "        Args:\n",
    "            node_type: Tipo de nodo (ej: \"Producto\")\n",
    "            properties: Diccionario con propiedades del nodo\n",
    "        \"\"\"\n",
    "        # Construir query Cypher\n",
    "        props_str = \", \".join([f\"{k}: ${k}\" for k in properties.keys()])\n",
    "        query = f\"CREATE (n:{node_type} {{{props_str}}})\"\n",
    "        \n",
    "        self.execute_query(query, properties)\n",
    "    \n",
    "    def create_relationship(self, from_id: str, to_id: str, rel_type: str, properties: Dict = None):\n",
    "        \"\"\"\n",
    "        Crea una relaci√≥n entre dos nodos\n",
    "        \n",
    "        Args:\n",
    "            from_id: ID del nodo origen\n",
    "            to_id: ID del nodo destino\n",
    "            rel_type: Tipo de relaci√≥n\n",
    "            properties: Propiedades de la relaci√≥n\n",
    "        \"\"\"\n",
    "        query = f\"\"\"\n",
    "        MATCH (a {{id: $from_id}})\n",
    "        MATCH (b {{id: $to_id}})\n",
    "        CREATE (a)-[r:{rel_type}]->(b)\n",
    "        \"\"\"\n",
    "        \n",
    "        if properties:\n",
    "            props_str = \", \".join([f\"r.{k} = ${k}\" for k in properties.keys()])\n",
    "            query += f\" SET {props_str}\"\n",
    "        \n",
    "        params = {\"from_id\": from_id, \"to_id\": to_id}\n",
    "        if properties:\n",
    "            params.update(properties)\n",
    "        \n",
    "        self.execute_query(query, params)\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Obtiene estad√≠sticas de la base de datos\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        # Contar nodos\n",
    "        result = self.execute_query(\"MATCH (n) RETURN count(n) as total\")\n",
    "        stats['total_nodos'] = result[0]['total'] if result else 0\n",
    "        \n",
    "        # Contar relaciones\n",
    "        result = self.execute_query(\"MATCH ()-[r]->() RETURN count(r) as total\")\n",
    "        stats['total_relaciones'] = result[0]['total'] if result else 0\n",
    "        \n",
    "        # Contar relaciones por tipo\n",
    "        result = self.execute_query(\"\"\"\n",
    "            MATCH ()-[r]->()\n",
    "            RETURN type(r) as tipo, count(r) as cantidad\n",
    "            ORDER BY cantidad DESC\n",
    "        \"\"\")\n",
    "        stats['relaciones_por_tipo'] = {row['tipo']: row['cantidad'] for row in result}\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Crear conexi√≥n global a Memgraph\n",
    "try:\n",
    "    graph_db = MemgraphConnection()\n",
    "    stats = graph_db.get_stats()\n",
    "    print(f\"Nodos en base: {stats['total_nodos']}\")\n",
    "    print(f\"Relaciones en base: {stats['total_relaciones']}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nNo se pudo conectar a Memgraph. Aseg√∫rate de que est√© corriendo.\")\n",
    "    graph_db = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d5d069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo relaciones entre productos...\n",
      "\n",
      "Relaciones extra√≠das:\n",
      "  - misma_categoria: 16387 relaciones\n",
      "  - misma_subcategoria: 4266 relaciones\n",
      "  - misma_marca: 3198 relaciones\n",
      "  - similar_precio: 8079 relaciones\n",
      "  - mismo_voltaje: 14878 relaciones\n",
      "\n",
      "Relaciones extra√≠das:\n",
      "  - misma_categoria: 16387 relaciones\n",
      "  - misma_subcategoria: 4266 relaciones\n",
      "  - misma_marca: 3198 relaciones\n",
      "  - similar_precio: 8079 relaciones\n",
      "  - mismo_voltaje: 14878 relaciones\n"
     ]
    }
   ],
   "source": [
    "def extraer_relaciones_productos(df: pd.DataFrame) -> Dict[str, List[Dict]]:\n",
    "    \"\"\"\n",
    "    Extrae diferentes tipos de relaciones entre productos del DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        Dict con diferentes tipos de relaciones:\n",
    "        - misma_categoria: productos de la misma categor√≠a\n",
    "        - misma_subcategoria: productos de la misma subcategor√≠a\n",
    "        - misma_marca: productos de la misma marca\n",
    "        - similar_precio: productos con precio similar (¬±20%)\n",
    "        - mismo_voltaje: productos con el mismo voltaje (compatibilidad)\n",
    "    \"\"\"\n",
    "    relaciones = {\n",
    "        'misma_categoria': [],\n",
    "        'misma_subcategoria': [],\n",
    "        'misma_marca': [],\n",
    "        'similar_precio': [],\n",
    "        'mismo_voltaje': []\n",
    "    }\n",
    "    \n",
    "    print(\"Extrayendo relaciones entre productos...\")\n",
    "    \n",
    "    # 1. Relaciones por categor√≠a\n",
    "    for categoria in df['categoria'].unique():\n",
    "        productos_cat = df[df['categoria'] == categoria]['id_producto'].tolist()\n",
    "        for i, prod1 in enumerate(productos_cat):\n",
    "            for prod2 in productos_cat[i+1:]:\n",
    "                relaciones['misma_categoria'].append({\n",
    "                    'from': prod1,\n",
    "                    'to': prod2,\n",
    "                    'categoria': categoria\n",
    "                })\n",
    "    \n",
    "    # 2. Relaciones por subcategor√≠a\n",
    "    for subcategoria in df['subcategoria'].unique():\n",
    "        productos_subcat = df[df['subcategoria'] == subcategoria]['id_producto'].tolist()\n",
    "        for i, prod1 in enumerate(productos_subcat):\n",
    "            for prod2 in productos_subcat[i+1:]:\n",
    "                relaciones['misma_subcategoria'].append({\n",
    "                    'from': prod1,\n",
    "                    'to': prod2,\n",
    "                    'subcategoria': subcategoria\n",
    "                })\n",
    "    \n",
    "    # 3. Relaciones por marca\n",
    "    for marca in df['marca'].unique():\n",
    "        productos_marca = df[df['marca'] == marca]['id_producto'].tolist()\n",
    "        for i, prod1 in enumerate(productos_marca):\n",
    "            for prod2 in productos_marca[i+1:]:\n",
    "                relaciones['misma_marca'].append({\n",
    "                    'from': prod1,\n",
    "                    'to': prod2,\n",
    "                    'marca': marca\n",
    "                })\n",
    "    \n",
    "    # 4. Relaciones por precio similar (¬±20%)\n",
    "    for idx, row in df.iterrows():\n",
    "        precio = row['precio_usd']\n",
    "        margen = precio * 0.20\n",
    "        similares = df[\n",
    "            (df['precio_usd'] >= precio - margen) &\n",
    "            (df['precio_usd'] <= precio + margen) &\n",
    "            (df['id_producto'] != row['id_producto'])\n",
    "        ]\n",
    "        \n",
    "        for _, sim in similares.iterrows():\n",
    "            # Evitar duplicados (solo A->B, no B->A)\n",
    "            if row['id_producto'] < sim['id_producto']:\n",
    "                relaciones['similar_precio'].append({\n",
    "                    'from': row['id_producto'],\n",
    "                    'to': sim['id_producto'],\n",
    "                    'precio_ref': precio,\n",
    "                    'diferencia_pct': abs((sim['precio_usd'] - precio) / precio * 100)\n",
    "                })\n",
    "    \n",
    "    # 5. Relaciones por mismo voltaje (compatibilidad)\n",
    "    for voltaje in df['voltaje'].dropna().unique():\n",
    "        productos_volt = df[df['voltaje'] == voltaje]['id_producto'].tolist()\n",
    "        for i, prod1 in enumerate(productos_volt):\n",
    "            for prod2 in productos_volt[i+1:]:\n",
    "                relaciones['mismo_voltaje'].append({\n",
    "                    'from': prod1,\n",
    "                    'to': prod2,\n",
    "                    'voltaje': voltaje\n",
    "                })\n",
    "    \n",
    "    # Resumen\n",
    "    print(\"\\nRelaciones extra√≠das:\")\n",
    "    for tipo, lista in relaciones.items():\n",
    "        print(f\"  - {tipo}: {len(lista)} relaciones\")\n",
    "    \n",
    "    return relaciones\n",
    "\n",
    "# Extraer relaciones\n",
    "relaciones_productos = extraer_relaciones_productos(df_productos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a67164ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Productos ya cargados en Memgraph\n"
     ]
    }
   ],
   "source": [
    "def cargar_productos_grafo(graph_db: MemgraphConnection, df: pd.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    Carga los productos como nodos en Memgraph\n",
    "    Cada producto se crea con todas sus propiedades\n",
    "    \n",
    "    Args:\n",
    "        graph_db: Conexi√≥n a Memgraph\n",
    "        df: DataFrame con los productos\n",
    "    \n",
    "    Returns:\n",
    "        True si se carg√≥ exitosamente\n",
    "    \"\"\"\n",
    "    print(\"Cargando productos en Memgraph...\")\n",
    "    \n",
    "    if graph_db is None:\n",
    "        print(\"‚úó No hay conexi√≥n a Memgraph\")\n",
    "        return False\n",
    "    \n",
    "    # Limpiar base de datos primero\n",
    "    graph_db.clear_database()\n",
    "    \n",
    "    # Cargar productos en lotes para mejor rendimiento\n",
    "    batch_size = 100\n",
    "    total = len(df)\n",
    "    \n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Construir query para el lote\n",
    "        for idx, row in batch.iterrows():\n",
    "            properties = row.fillna(\"\").to_dict()\n",
    "            # Asegurarse de que tenga 'id'\n",
    "            if 'id_producto' in properties and 'id' not in properties:\n",
    "                properties['id'] = properties['id_producto']\n",
    "            \n",
    "            graph_db.create_node('Producto', properties)\n",
    "        \n",
    "        if (i + batch_size) % 500 == 0 or (i + batch_size) >= total:\n",
    "            print(f\"  Cargados {min(i + batch_size, total)}/{total} productos...\")\n",
    "    \n",
    "    print(f\"{len(df)} productos cargados exitosamente\")\n",
    "    \n",
    "    # Verificar carga\n",
    "    stats = graph_db.get_stats()\n",
    "    print(f\"Total de nodos en grafo: {stats['total_nodos']}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Cargar productos si hay conexi√≥n\n",
    "if graph_db is not None:\n",
    "    stats = graph_db.get_stats()\n",
    "else:\n",
    "    stats = {'total_nodos': 0}\n",
    "\n",
    "\n",
    "if stats['total_nodos'] == 0:\n",
    "    cargar_productos_grafo(graph_db, df_productos)\n",
    "elif stats['total_nodos'] != 0:\n",
    "    print(\"Productos ya cargados en Memgraph\")\n",
    "elif graph_db is None:\n",
    "    print(\"Skipping - No hay conexi√≥n a Memgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3df1f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relaciones ya cargadas en Memgraph\n"
     ]
    }
   ],
   "source": [
    "def cargar_relaciones_grafo(graph_db: MemgraphConnection, relaciones: Dict[str, List[Dict]]) -> bool:\n",
    "    \"\"\"\n",
    "    Carga las relaciones entre productos en Memgraph\n",
    "    \n",
    "    Args:\n",
    "        graph_db: Conexi√≥n a Memgraph\n",
    "        relaciones: Diccionario con listas de relaciones por tipo\n",
    "    \n",
    "    Returns:\n",
    "        True si se carg√≥ exitosamente\n",
    "    \"\"\"\n",
    "    print(\"Cargando relaciones en Memgraph...\")\n",
    "    \n",
    "    if graph_db is None:\n",
    "        print(\"‚úó No hay conexi√≥n a Memgraph\")\n",
    "        return False\n",
    "    \n",
    "    total_cargadas = 0\n",
    "    \n",
    "    # 1. MISMA_CATEGORIA\n",
    "    if relaciones['misma_categoria']:\n",
    "        count = 0\n",
    "        for rel in relaciones['misma_categoria'][:1000]:  # Limitar para no sobrecargar\n",
    "            graph_db.create_relationship(\n",
    "                rel['from'], \n",
    "                rel['to'], \n",
    "                'MISMA_CATEGORIA',\n",
    "                {'categoria': rel['categoria']}\n",
    "            )\n",
    "            count += 1\n",
    "        print(f\"  {count} relaciones MISMA_CATEGORIA\")\n",
    "        total_cargadas += count\n",
    "    \n",
    "    # 2. MISMA_SUBCATEGORIA\n",
    "    if relaciones['misma_subcategoria']:\n",
    "        count = 0\n",
    "        for rel in relaciones['misma_subcategoria'][:1000]:\n",
    "            graph_db.create_relationship(\n",
    "                rel['from'], \n",
    "                rel['to'], \n",
    "                'MISMA_SUBCATEGORIA',\n",
    "                {'subcategoria': rel['subcategoria']}\n",
    "            )\n",
    "            count += 1\n",
    "        print(f\"  {count} relaciones MISMA_SUBCATEGORIA\")\n",
    "        total_cargadas += count\n",
    "    \n",
    "    # 3. MISMA_MARCA\n",
    "    if relaciones['misma_marca']:\n",
    "        count = 0\n",
    "        for rel in relaciones['misma_marca'][:1000]:\n",
    "            graph_db.create_relationship(\n",
    "                rel['from'], \n",
    "                rel['to'], \n",
    "                'MISMA_MARCA',\n",
    "                {'marca': rel['marca']}\n",
    "            )\n",
    "            count += 1\n",
    "        print(f\"  {count} relaciones MISMA_MARCA\")\n",
    "        total_cargadas += count\n",
    "    \n",
    "    # 4. SIMILAR_PRECIO\n",
    "    if relaciones['similar_precio']:\n",
    "        count = 0\n",
    "        for rel in relaciones['similar_precio'][:500]:\n",
    "            graph_db.create_relationship(\n",
    "                rel['from'], \n",
    "                rel['to'], \n",
    "                'SIMILAR_PRECIO',\n",
    "                {\n",
    "                    'precio_ref': rel['precio_ref'],\n",
    "                    'diferencia_pct': rel['diferencia_pct']\n",
    "                }\n",
    "            )\n",
    "            count += 1\n",
    "        print(f\"  {count} relaciones SIMILAR_PRECIO\")\n",
    "        total_cargadas += count\n",
    "    \n",
    "    # 5. MISMO_VOLTAJE\n",
    "    if relaciones['mismo_voltaje']:\n",
    "        count = 0\n",
    "        for rel in relaciones['mismo_voltaje'][:1000]:\n",
    "            graph_db.create_relationship(\n",
    "                rel['from'], \n",
    "                rel['to'], \n",
    "                'MISMO_VOLTAJE',\n",
    "                {'voltaje': rel['voltaje']}\n",
    "            )\n",
    "            count += 1\n",
    "        print(f\"  {count} relaciones MISMO_VOLTAJE\")\n",
    "        total_cargadas += count\n",
    "    \n",
    "    print(f\"Total de {total_cargadas} relaciones cargadas\")\n",
    "    \n",
    "    # Verificar carga\n",
    "    stats = graph_db.get_stats()\n",
    "    print(f\"Total de relaciones en grafo: {stats['total_relaciones']}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "if graph_db is not None:\n",
    "    stats = graph_db.get_stats()\n",
    "else:\n",
    "    stats = {'total_nodos': 0}\n",
    "\n",
    "\n",
    "if stats['total_relaciones'] == 0:\n",
    "    cargar_relaciones_grafo(graph_db, relaciones_productos)\n",
    "elif stats['total_relaciones'] != 0:\n",
    "    print(\"Relaciones ya cargadas en Memgraph\")\n",
    "elif graph_db is None:\n",
    "    print(\"Skipping - No hay conexi√≥n a Memgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02249f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema de Neo4j para LLM generado\n",
      "  Longitud: 2738 caracteres ~ 912 tokens\n"
     ]
    }
   ],
   "source": [
    "def get_schema_context_for_cypher() -> str:\n",
    "    \"\"\"\n",
    "    Genera contexto sobre el schema del grafo para el LLM\n",
    "    \"\"\"\n",
    "    context = \"\"\"\n",
    "# SCHEMA DE LA BASE DE DATOS DE GRAFOS NEO4J\n",
    "\n",
    "## NODOS (Nodes)\n",
    "### Producto\n",
    "Propiedades:\n",
    "- id: String (identificador √∫nico, ej: \"P0001\")\n",
    "- nombre: String (nombre del producto)\n",
    "- categoria: String (categor√≠a principal: \"Cocina\", \"Refrigeraci√≥n\", \"Climatizaci√≥n\", etc.)\n",
    "- subcategoria: String (subcategor√≠a espec√≠fica)\n",
    "- marca: String (marca del producto: \"TechHome\", \"KitchenPro\", \"HomeChef\", \"ChefMaster\", \"CookElite\")\n",
    "- precio_usd: Float (precio en d√≥lares)\n",
    "- stock: Integer (unidades disponibles)\n",
    "- color: String (color del producto)\n",
    "- potencia_w: Float (potencia en watts, puede ser null)\n",
    "- capacidad: String (capacidad del producto, puede ser null)\n",
    "- voltaje: String (voltaje requerido: \"12V\", \"110V\", \"220V\", \"110-220V\", puede ser null)\n",
    "- peso_kg: Float (peso en kilogramos)\n",
    "- garantia_meses: Integer (meses de garant√≠a)\n",
    "- descripcion: String (descripci√≥n detallada)\n",
    "\n",
    "## RELACIONES (Relationships)\n",
    "1. **MISMA_CATEGORIA**: Conecta productos de la misma categor√≠a\n",
    "   - Propiedades: categoria (String)\n",
    "   \n",
    "2. **MISMA_SUBCATEGORIA**: Conecta productos de la misma subcategor√≠a\n",
    "   - Propiedades: subcategoria (String)\n",
    "   \n",
    "3. **MISMA_MARCA**: Conecta productos de la misma marca\n",
    "   - Propiedades: marca (String)\n",
    "   \n",
    "4. **SIMILAR_PRECIO**: Conecta productos con precios similares (¬±20%)\n",
    "   - Propiedades: precio_ref (Float), diferencia_pct (Float)\n",
    "   \n",
    "5. **MISMO_VOLTAJE**: Conecta productos con el mismo voltaje (compatibilidad el√©ctrica)\n",
    "   - Propiedades: voltaje (String)\n",
    "\n",
    "## EJEMPLOS DE CONSULTAS CYPHER\n",
    "\n",
    "### Buscar producto por ID:\n",
    "```cypher\n",
    "MATCH (p:Producto {id: 'P0001'})\n",
    "RETURN p\n",
    "```\n",
    "\n",
    "### Buscar productos de una categor√≠a:\n",
    "```cypher\n",
    "MATCH (p:Producto)\n",
    "WHERE p.categoria = 'Cocina'\n",
    "RETURN p.id, p.nombre, p.precio_usd\n",
    "```\n",
    "\n",
    "### Buscar productos relacionados por marca:\n",
    "```cypher\n",
    "MATCH (p1:Producto {id: 'P0001'})-[:MISMA_MARCA]->(p2:Producto)\n",
    "RETURN p2.id, p2.nombre, p2.precio_usd\n",
    "```\n",
    "\n",
    "### Buscar productos similares por precio:\n",
    "```cypher\n",
    "MATCH (p1:Producto {id: 'P0001'})-[r:SIMILAR_PRECIO]-(p2:Producto)\n",
    "WHERE r.diferencia_pct < 10\n",
    "RETURN p2.id, p2.nombre, p2.precio_usd, r.diferencia_pct\n",
    "```\n",
    "\n",
    "### Buscar productos compatibles por voltaje:\n",
    "```cypher\n",
    "MATCH (p1:Producto)-[r:MISMO_VOLTAJE]-(p2:Producto)\n",
    "WHERE p1.id = 'P0001'\n",
    "RETURN p2.id, p2.nombre, r.voltaje\n",
    "```\n",
    "\n",
    "### Buscar productos de misma categor√≠a y marca:\n",
    "```cypher\n",
    "MATCH (p:Producto)\n",
    "WHERE p.categoria = 'Cocina' AND p.marca = 'TechHome'\n",
    "RETURN p.id, p.nombre, p.precio_usd\n",
    "ORDER BY p.precio_usd ASC\n",
    "LIMIT 10\n",
    "```\n",
    "\n",
    "### Encontrar productos relacionados en m√∫ltiples dimensiones:\n",
    "```cypher\n",
    "MATCH (p1:Producto {id: 'P0001'})\n",
    "MATCH (p1)-[:MISMA_CATEGORIA]->(p2:Producto)\n",
    "MATCH (p2)-[:SIMILAR_PRECIO]->(p3:Producto)\n",
    "RETURN DISTINCT p3.id, p3.nombre, p3.precio_usd\n",
    "LIMIT 5\n",
    "```\n",
    "\"\"\"\n",
    "    return context\n",
    "\n",
    "# Generar contexto\n",
    "cypher_schema_context = get_schema_context_for_cypher()\n",
    "print(\"Schema de Neo4j para LLM generado\")\n",
    "print(f\"  Longitud: {len(cypher_schema_context)} caracteres ~ {len(cypher_schema_context)//3} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0ec79a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba de conversi√≥n NL ‚Üí Cypher:\n",
      "\n",
      "Consulta: Mu√©strame todos los productos de la marca TechHome\n",
      "Cypher generado:\n",
      "MATCH (p:Producto) WHERE p.marca = 'TechHome' RETURN p.id, p.nombre, p.precio_usd, p.categoria, p.stock LIMIT 20\n",
      "Consulta: Mu√©strame todos los productos de la marca TechHome\n",
      "Cypher generado:\n",
      "MATCH (p:Producto) WHERE p.marca = 'TechHome' RETURN p.id, p.nombre, p.precio_usd, p.categoria, p.stock LIMIT 20\n"
     ]
    }
   ],
   "source": [
    "def nl_to_cypher(llm, consulta_usuario: str, schema_context: str) -> str:\n",
    "    \"\"\"\n",
    "    Convierte una consulta en lenguaje natural a una query Cypher v√°lida\n",
    "    \n",
    "    Args:\n",
    "        llm: Modelo de lenguaje (Gemini, GPT, etc.)\n",
    "        consulta_usuario: Pregunta del usuario en lenguaje natural\n",
    "        schema_context: Contexto del schema de Neo4j\n",
    "    \n",
    "    Returns:\n",
    "        Query Cypher v√°lida como string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Eres un experto en Neo4j y el lenguaje de consulta Cypher.\n",
    "\n",
    "{schema_context}\n",
    "\n",
    "## TU TAREA\n",
    "Convierte la siguiente consulta en lenguaje natural a una query Cypher v√°lida.\n",
    "\n",
    "**REGLAS IMPORTANTES:**\n",
    "1. Devuelve SOLO la query Cypher, sin explicaciones adicionales\n",
    "2. No uses markdown (```cypher```) ni formato especial\n",
    "3. La query debe ser sint√°cticamente correcta\n",
    "4. Si la consulta pide \"mostrar\" o \"listar\", usa RETURN con las propiedades relevantes\n",
    "5. Usa LIMIT cuando sea apropiado (por defecto 20 para listados)\n",
    "6. Para b√∫squedas textuales, usa CONTAINS (case-insensitive: toLower())\n",
    "7. Las propiedades num√©ricas pueden compararse con >, <, =, >=, <=\n",
    "8. Si necesitas ordenar, usa ORDER BY\n",
    "\n",
    "**CONSULTA DEL USUARIO:**\n",
    "{consulta_usuario}\n",
    "\n",
    "**QUERY CYPHER:**\"\"\"\n",
    "\n",
    "    # Generar respuesta\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Limpiar respuesta (remover markdown si existe)\n",
    "    cypher_query = response.strip()\n",
    "    if cypher_query.startswith(\"```cypher\"):\n",
    "        cypher_query = cypher_query.replace(\"```cypher\", \"\").replace(\"```\", \"\").strip()\n",
    "    elif cypher_query.startswith(\"```\"):\n",
    "        cypher_query = cypher_query.replace(\"```\", \"\").strip()\n",
    "    \n",
    "    return cypher_query\n",
    "\n",
    "# Prueba r√°pida\n",
    "print(\"Prueba de conversi√≥n NL ‚Üí Cypher:\\n\")\n",
    "consulta_test = \"Mu√©strame todos los productos de la marca TechHome\"\n",
    "cypher_test = nl_to_cypher(llm, consulta_test, cypher_schema_context)\n",
    "print(f\"Consulta: {consulta_test}\")\n",
    "print(f\"Cypher generado:\\n{cypher_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc5f12dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funci√≥n consulta_grafo() definida para Memgraph\n"
     ]
    }
   ],
   "source": [
    "def consulta_grafo(\n",
    "    llm,\n",
    "    graph_db: MemgraphConnection,\n",
    "    consulta_usuario: str,\n",
    "    schema_context: str,\n",
    "    verbose: bool = False\n",
    ") -> Tuple[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Interfaz principal para consultar Memgraph usando lenguaje natural\n",
    "    \n",
    "    Args:\n",
    "        llm: Modelo de lenguaje\n",
    "        graph_db: Conexi√≥n a Memgraph\n",
    "        consulta_usuario: Pregunta en lenguaje natural\n",
    "        schema_context: Contexto del schema\n",
    "        verbose: Si mostrar informaci√≥n de debug\n",
    "    \n",
    "    Returns:\n",
    "        Tuple de (descripci√≥n_texto, dataframe_resultados)\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"CONSULTA AL GRAFO DE RELACIONES (MEMGRAPH)\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Consulta: {consulta_usuario}\\n\")\n",
    "    \n",
    "    if graph_db is None:\n",
    "        error_msg = \"No hay conexi√≥n a Memgraph\"\n",
    "        print(error_msg)\n",
    "        return error_msg, pd.DataFrame()\n",
    "    \n",
    "    # Paso 1: Convertir NL a Cypher\n",
    "    if verbose:\n",
    "        print(\"Generando query Cypher con LLM...\")\n",
    "    \n",
    "    try:\n",
    "        cypher_query = nl_to_cypher(llm, consulta_usuario, schema_context)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Query generada:\\n{cypher_query}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error al generar query Cypher: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg, pd.DataFrame()\n",
    "    \n",
    "    # Paso 2: Ejecutar query en Memgraph\n",
    "    if verbose:\n",
    "        print(\"Ejecutando query en Memgraph...\")\n",
    "    \n",
    "    try:\n",
    "        resultados = graph_db.execute_query(cypher_query)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Query ejecutada. Resultados obtenidos: {len(resultados)}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error al ejecutar query: {e}\"\n",
    "        print(error_msg)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return error_msg, pd.DataFrame()\n",
    "    \n",
    "    # Paso 3: Convertir a DataFrame\n",
    "    if not resultados:\n",
    "        msg = \"La consulta no devolvi√≥ resultados\"\n",
    "        if verbose:\n",
    "            print(msg)\n",
    "        return msg, pd.DataFrame()\n",
    "    \n",
    "    # Procesar resultados: si hay nodos completos, extraer propiedades\n",
    "    processed_results = []\n",
    "    for result in resultados:\n",
    "        processed_row = {}\n",
    "        for key, value in result.items():\n",
    "            if isinstance(value, dict):\n",
    "                # Si es un nodo completo, aplanar sus propiedades\n",
    "                for prop_key, prop_value in value.items():\n",
    "                    processed_row[f\"{key}.{prop_key}\"] = prop_value\n",
    "            else:\n",
    "                processed_row[key] = value\n",
    "        processed_results.append(processed_row)\n",
    "    \n",
    "    df_resultados = pd.DataFrame(processed_results)\n",
    "    \n",
    "    # Paso 4: Generar descripci√≥n con LLM\n",
    "    if verbose:\n",
    "        print(\"Generando descripci√≥n de resultados...\")\n",
    "    \n",
    "    try:\n",
    "        descripcion = generar_descripcion_resultados(llm, consulta_usuario, df_resultados)\n",
    "        if verbose:\n",
    "            print(f\"Descripci√≥n generada\\n\")\n",
    "    except Exception as e:\n",
    "        descripcion = f\"Se encontraron {len(df_resultados)} resultados para la consulta.\"\n",
    "        if verbose:\n",
    "            print(f\"Error generando descripci√≥n: {e}\")\n",
    "    \n",
    "    return descripcion, df_resultados\n",
    "\n",
    "def generar_descripcion_resultados(llm, consulta: str, df: pd.DataFrame) -> str:\n",
    "    \"\"\"Genera una descripci√≥n textual de los resultados\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"No se encontraron resultados para la consulta.\"\n",
    "    \n",
    "    # Resumen de datos\n",
    "    num_resultados = len(df)\n",
    "    columnas = list(df.columns)\n",
    "    \n",
    "    # Tomar muestra de resultados\n",
    "    muestra = df.head(3).to_dict('records')\n",
    "    \n",
    "    prompt = f\"\"\"Describe brevemente los resultados de esta consulta de base de datos de grafos.\n",
    "\n",
    "Consulta del usuario: {consulta}\n",
    "N√∫mero de resultados: {num_resultados}\n",
    "Columnas: {columnas}\n",
    "\n",
    "Muestra de resultados:\n",
    "{json.dumps(muestra, indent=2, ensure_ascii=False, default=str)}\n",
    "\n",
    "Genera una respuesta concisa (2-3 oraciones) que resuma los resultados de forma natural.\"\"\"\n",
    "\n",
    "    descripcion = llm.invoke(prompt)\n",
    "    return descripcion.strip()\n",
    "\n",
    "print(\"Funci√≥n consulta_grafo() definida para Memgraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0192a87",
   "metadata": {},
   "source": [
    "## 2. Creaci√≥n del Agente RAG\n",
    "\n",
    "Implementaci√≥n de herramientas (tools) para el agente que combinan las tres fuentes de datos:\n",
    "- **doc_search**: B√∫squeda h√≠brida en documentos con re-ranking\n",
    "- **table_search**: Consultas din√°micas en datos tabulares\n",
    "- **graph_search**: Consultas din√°micas en base de datos de grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90524e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def doc_search_tool(query: str, filter_tipo: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Busca informaci√≥n en documentos (manuales, FAQs, tickets, rese√±as) usando b√∫squeda h√≠brida con re-ranking.\n",
    "    \n",
    "    Usa esta herramienta cuando necesites:\n",
    "    - Informaci√≥n de manuales de productos (instalaci√≥n, uso, mantenimiento)\n",
    "    - Respuestas a preguntas frecuentes (FAQs)\n",
    "    - Soluciones de tickets de soporte t√©cnico\n",
    "    - Opiniones y rese√±as de usuarios\n",
    "    \n",
    "    Args:\n",
    "        query: La pregunta o consulta del usuario\n",
    "        filter_tipo: (Opcional) Tipo de documento: 'manual', 'faq', 'ticket', 'resena'\n",
    "    \n",
    "    Returns:\n",
    "        Texto con los documentos m√°s relevantes encontrados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Llamar a la funci√≥n de b√∫squeda h√≠brida\n",
    "        results = doc_search(query, n_results=3, filter_tipo=filter_tipo, use_rerank=True)\n",
    "        \n",
    "        # Formatear resultados\n",
    "        if not results['documents']:\n",
    "            return f\"No se encontraron documentos relevantes para: {query}\"\n",
    "        \n",
    "        response = f\"Resultados para '{query}' ({results['method']}):\\n\\n\"\n",
    "        \n",
    "        for i, doc in enumerate(results['documents'], 1):\n",
    "            tipo = doc['metadata'].get('tipo', 'desconocido')\n",
    "            score = doc['score']\n",
    "            text = doc['text'][:300]  # Limitar longitud\n",
    "            \n",
    "            response += f\"{i}. [{tipo.upper()}] (Relevancia: {score:.3f})\\n\"\n",
    "            response += f\"   {text}...\\n\\n\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error al buscar documentos: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def table_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Realiza consultas sobre el cat√°logo de productos usando lenguaje natural para consultar un dataframe de pandas.\n",
    "    \n",
    "    Usa esta herramienta cuando necesites:\n",
    "    - Buscar productos por precio, stock, marca, categor√≠a\n",
    "    - Comparar productos entre s√≠\n",
    "    - Obtener listados de productos m√°s baratos/caros\n",
    "    - Informaci√≥n espec√≠fica de productos por ID\n",
    "    - Listar categor√≠as o marcas disponibles\n",
    "    \n",
    "    Args:\n",
    "        query: Consulta en lenguaje natural sobre productos\n",
    "        \n",
    "    Returns:\n",
    "        Informaci√≥n estructurada sobre los productos encontrados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Llamar a la funci√≥n de consulta tabular\n",
    "        resultado = consulta_con_llm_tabular(llm, query)\n",
    "        \n",
    "        # Si el resultado es un DataFrame, formatearlo\n",
    "        if isinstance(resultado, pd.DataFrame):\n",
    "            if resultado.empty:\n",
    "                return f\"No se encontraron productos para la consulta: {query}\"\n",
    "            \n",
    "            # Limitar a 10 filas para no saturar el contexto\n",
    "            df_limited = resultado.head(10)\n",
    "            \n",
    "            response = f\"Resultados para '{query}':\\n\\n\"\n",
    "            response += f\"Total de productos encontrados: {len(resultado)}\\n\"\n",
    "            response += f\"Mostrando primeros {len(df_limited)} resultados:\\n\\n\"\n",
    "            response += df_limited.to_string(index=False)\n",
    "            \n",
    "            if len(resultado) > 10:\n",
    "                response += f\"\\n\\n(Hay {len(resultado) - 10} productos m√°s...)\"\n",
    "            \n",
    "            return response\n",
    "        \n",
    "        # Si es otro tipo de resultado (lista, dict, etc.)\n",
    "        elif isinstance(resultado, (list, dict)):\n",
    "            return f\"Resultados para '{query}':\\n{json.dumps(resultado, indent=2, ensure_ascii=False)}\"\n",
    "        \n",
    "        else:\n",
    "            return str(resultado)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error al consultar productos: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def graph_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Realiza consultas sobre relaciones entre productos en la base de datos de grafos.\n",
    "    \n",
    "    Usa esta herramienta cuando necesites:\n",
    "    - Encontrar productos relacionados por categor√≠a, marca o precio\n",
    "    - Productos compatibles por voltaje\n",
    "    - Productos similares o alternativos\n",
    "    - Relaciones complejas entre productos\n",
    "    \n",
    "    Args:\n",
    "        query: Consulta en lenguaje natural sobre relaciones entre productos\n",
    "        \n",
    "    Returns:\n",
    "        Descripci√≥n y datos de las relaciones encontradas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar conexi√≥n\n",
    "        if graph_db is None:\n",
    "            return \"Error: No hay conexi√≥n disponible con la base de datos de grafos.\"\n",
    "        \n",
    "        # Obtener el contexto del schema\n",
    "        schema_ctx = get_schema_context_for_cypher()\n",
    "        \n",
    "        # Llamar a la funci√≥n de consulta de grafos\n",
    "        descripcion, df_resultados = consulta_grafo(\n",
    "            llm=llm,\n",
    "            graph_db=graph_db,\n",
    "            consulta_usuario=query,\n",
    "            schema_context=schema_ctx,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Formatear respuesta\n",
    "        response = f\"Consulta de grafos: '{query}'\\n\\n\"\n",
    "        response += f\"{descripcion}\\n\\n\"\n",
    "        \n",
    "        if not df_resultados.empty:\n",
    "            # Limitar a 10 resultados\n",
    "            df_limited = df_resultados.head(10)\n",
    "            response += f\"Detalles ({len(df_limited)} de {len(df_resultados)} resultados):\\n\\n\"\n",
    "            response += df_limited.to_string(index=False)\n",
    "            \n",
    "            if len(df_resultados) > 10:\n",
    "                response += f\"\\n\\n(Hay {len(df_resultados) - 10} resultados m√°s...)\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error al consultar base de grafos: {str(e)}\"\n",
    "\n",
    "\n",
    "# Lista de herramientas disponibles para el agente\n",
    "tools = [doc_search_tool, table_search_tool, graph_search_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670be571",
   "metadata": {},
   "source": [
    "### Descripci√≥n de las herramientas\n",
    "\n",
    "**1. doc_search_tool**\n",
    "- **Prop√≥sito**: B√∫squeda en documentos de texto (manuales, FAQs, tickets, rese√±as)\n",
    "- **Tecnolog√≠a**: B√∫squeda h√≠brida (sem√°ntica + BM25) con re-ranking\n",
    "- **Uso**: Preguntas sobre instalaci√≥n, uso, soluci√≥n de problemas, opiniones\n",
    "\n",
    "**2. table_search_tool**\n",
    "- **Prop√≥sito**: Consultas sobre el cat√°logo de productos\n",
    "- **Tecnolog√≠a**: LLM traduce lenguaje natural a funciones Python\n",
    "- **Uso**: Buscar por precio, stock, marca, comparaciones, listados\n",
    "\n",
    "**3. graph_search_tool**\n",
    "- **Prop√≥sito**: Consultas sobre relaciones entre productos\n",
    "- **Tecnolog√≠a**: LLM traduce lenguaje natural a queries Cypher\n",
    "- **Uso**: Productos relacionados, similares, compatibles, alternativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f6ddc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_historicas_df = pd.read_csv('data/raw/ventas_historicas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dec25e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id_venta           10000 non-null  object \n",
      " 1   fecha              10000 non-null  object \n",
      " 2   hora               10000 non-null  object \n",
      " 3   id_producto        10000 non-null  object \n",
      " 4   nombre_producto    10000 non-null  object \n",
      " 5   id_vendedor        10000 non-null  object \n",
      " 6   nombre_vendedor    10000 non-null  object \n",
      " 7   sucursal           10000 non-null  object \n",
      " 8   cantidad           10000 non-null  int64  \n",
      " 9   precio_unitario    10000 non-null  float64\n",
      " 10  descuento_pct      10000 non-null  int64  \n",
      " 11  total              10000 non-null  float64\n",
      " 12  metodo_pago        10000 non-null  object \n",
      " 13  cliente_nombre     10000 non-null  object \n",
      " 14  cliente_provincia  10000 non-null  object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "ventas_historicas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7923a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
